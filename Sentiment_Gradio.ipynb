{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0754367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "972b8547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "  result = set(stopwords.words('english'))\n",
    "  filter = str(text).split()\n",
    "  return \" \".join([word for word in filter if word not in result])\n",
    "\n",
    "p = string.punctuation\n",
    "def remove_punctuations(text):\n",
    "  t = str.maketrans(\"\",\"\",p)\n",
    "  return text.translate(t)\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "st = nltk.PorterStemmer()\n",
    "def stem_words(data):\n",
    "  text = [st.stem(word) for word in data]\n",
    "  return data\n",
    "lm = nltk.WordNetLemmatizer()\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "182e6285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satwik\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Satwik\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Satwik\\anaconda3\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained model and vectorizer\n",
    "model = joblib.load(\"logistic_regression_model.pkl\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Define the function for sentiment analysis\n",
    "def predict_sentiment(paragraph):\n",
    "    # Vectorize the input paragraph using the TFIDF vectorizer\n",
    "    paragraph = paragraph.lower()\n",
    "    paragraph = remove_stopwords(paragraph)\n",
    "    paragraph = remove_punctuations(paragraph)\n",
    "    paragraph = tokenizer.tokenize(paragraph)\n",
    "    para = stem_words(paragraph)\n",
    "    para = lemmatizer_on_text(para)\n",
    "    para = ' '.join(para)\n",
    "    vectorized_text = vectorizer.transform([para])\n",
    "    \n",
    "    # Predict sentiment using the pre-trained Logistic Regression model\n",
    "    prediction = model.predict(vectorized_text)\n",
    "\n",
    "    # Return the result as positive or negative sentiment\n",
    "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict_sentiment,\n",
    "    inputs=gr.Textbox(),\n",
    "    outputs=gr.Textbox(),\n",
    "    title=\"Customer Sentiment Analysis\",\n",
    "    live=False,\n",
    "    description=\"Enter text to predict its Sentiment.\",\n",
    "    allow_flagging = \"never\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio interface\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee871b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
